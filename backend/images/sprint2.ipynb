{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Using cached torch-2.6.0-cp39-cp39-manylinux1_x86_64.whl (766.7 MB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.21.0-cp39-cp39-manylinux1_x86_64.whl (7.2 MB)\n",
      "Collecting Pillow\n",
      "  Using cached pillow-11.1.0-cp39-cp39-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "Collecting efficientnet-pytorch\n",
      "  Using cached efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/lib/python3.9/site-packages (from -r r.txt (line 6)) (2.25.1)\n",
      "Collecting validators\n",
      "  Using cached validators-0.34.0-py3-none-any.whl (43 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /uolstore/home/student_lnxhome01/sc21cm/.local/lib/python3.9/site-packages (from torch->-r r.txt (line 1)) (12.4.127)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /uolstore/home/student_lnxhome01/sc21cm/.local/lib/python3.9/site-packages (from torch->-r r.txt (line 1)) (12.4.5.8)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /uolstore/home/student_lnxhome01/sc21cm/.local/lib/python3.9/site-packages (from torch->-r r.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /uolstore/home/student_lnxhome01/sc21cm/.local/lib/python3.9/site-packages (from torch->-r r.txt (line 1)) (0.6.2)\n",
      "Requirement already satisfied: triton==3.2.0 in /uolstore/home/student_lnxhome01/sc21cm/.local/lib/python3.9/site-packages (from torch->-r r.txt (line 1)) (3.2.0)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /uolstore/home/student_lnxhome01/sc21cm/.local/lib/python3.9/site-packages (from torch->-r r.txt (line 1)) (11.6.1.9)\n",
      "Collecting fsspec\n",
      "  Using cached fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /uolstore/home/student_lnxhome01/sc21cm/.local/lib/python3.9/site-packages (from torch->-r r.txt (line 1)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /uolstore/home/student_lnxhome01/sc21cm/.local/lib/python3.9/site-packages (from torch->-r r.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /uolstore/home/student_lnxhome01/sc21cm/.local/lib/python3.9/site-packages (from torch->-r r.txt (line 1)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /uolstore/home/student_lnxhome01/sc21cm/.local/lib/python3.9/site-packages (from torch->-r r.txt (line 1)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /uolstore/home/student_lnxhome01/sc21cm/.local/lib/python3.9/site-packages (from torch->-r r.txt (line 1)) (10.3.5.147)\n",
      "Requirement already satisfied: sympy==1.13.1 in /uolstore/home/student_lnxhome01/sc21cm/.local/lib/python3.9/site-packages (from torch->-r r.txt (line 1)) (1.13.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Collecting jinja2\n",
      "  Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /uolstore/home/student_lnxhome01/sc21cm/.local/lib/python3.9/site-packages (from sympy==1.13.1->torch->-r r.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/lib64/python3.9/site-packages (from torchvision->-r r.txt (line 2)) (1.20.1)\n",
      "Collecting scipy>=1.6.0\n",
      "  Using cached scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Collecting joblib>=1.2.0\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/lib/python3.9/site-packages (from requests->-r r.txt (line 6)) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3.9/site-packages (from requests->-r r.txt (line 6)) (1.26.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3.9/site-packages (from requests->-r r.txt (line 6)) (2.10)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /uolstore/home/student_lnxhome01/sc21cm/.local/lib/python3.9/site-packages (from jinja2->torch->-r r.txt (line 1)) (3.0.2)\n",
      "Using legacy 'setup.py install' for efficientnet-pytorch, since package 'wheel' is not installed.\n",
      "Installing collected packages: nvidia-cudnn-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, numpy, networkx, jinja2, fsspec, filelock, torch, threadpoolctl, scipy, Pillow, joblib, validators, torchvision, scikit-learn, efficientnet-pytorch\n",
      "    Running setup.py install for efficientnet-pytorch ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed Pillow-11.1.0 efficientnet-pytorch-0.7.1 filelock-3.17.0 fsspec-2025.2.0 jinja2-3.1.5 joblib-1.4.2 networkx-3.2.1 numpy-2.0.2 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 scikit-learn-1.6.1 scipy-1.13.1 threadpoolctl-3.5.0 torch-2.6.0 torchvision-0.21.0 validators-0.34.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r r.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda for training and inference\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "\n",
    "# Set device (MPS for Mac, CUDA for GPU, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.backends.cuda.is_built() else \"mps\" if torch.backends.mps.is_built() else \"cpu\")\n",
    "print(f'Using {device} for training and inference')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /uolstore/home/users/sc21cm/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
      "/uolstore/home/users/sc21cm/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "/uolstore/home/users/sc21cm/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "Using cache found in /uolstore/home/users/sc21cm/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (stem): Sequential(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (activation): SiLU(inplace=True)\n",
       "  )\n",
       "  (layers): Sequential(\n",
       "    (0): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=32, out_features=8, bias=True)\n",
       "          (expand): Linear(in_features=8, out_features=32, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=96, out_features=4, bias=True)\n",
       "          (expand): Linear(in_features=4, out_features=96, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block1): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (bn): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=144, out_features=6, bias=True)\n",
       "          (expand): Linear(in_features=6, out_features=144, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "          (bn): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=144, out_features=6, bias=True)\n",
       "          (expand): Linear(in_features=6, out_features=144, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block1): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=240, out_features=10, bias=True)\n",
       "          (expand): Linear(in_features=10, out_features=240, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=240, out_features=10, bias=True)\n",
       "          (expand): Linear(in_features=10, out_features=240, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block1): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=480, out_features=20, bias=True)\n",
       "          (expand): Linear(in_features=20, out_features=480, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block2): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=480, out_features=20, bias=True)\n",
       "          (expand): Linear(in_features=20, out_features=480, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "          (bn): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=480, out_features=20, bias=True)\n",
       "          (expand): Linear(in_features=20, out_features=480, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block1): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=672, out_features=28, bias=True)\n",
       "          (expand): Linear(in_features=28, out_features=672, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block2): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=672, out_features=28, bias=True)\n",
       "          (expand): Linear(in_features=28, out_features=672, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=672, out_features=28, bias=True)\n",
       "          (expand): Linear(in_features=28, out_features=672, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block1): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=1152, out_features=48, bias=True)\n",
       "          (expand): Linear(in_features=48, out_features=1152, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block2): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=1152, out_features=48, bias=True)\n",
       "          (expand): Linear(in_features=48, out_features=1152, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "      (block3): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=1152, out_features=48, bias=True)\n",
       "          (expand): Linear(in_features=48, out_features=1152, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (block0): MBConvBlock(\n",
       "        (expand): Sequential(\n",
       "          (conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (depsep): Sequential(\n",
       "          (conv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "          (bn): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SequentialSqueezeAndExcitation(\n",
       "          (squeeze): Linear(in_features=1152, out_features=48, bias=True)\n",
       "          (expand): Linear(in_features=48, out_features=1152, bias=True)\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul_a_quantizer): Identity()\n",
       "          (mul_b_quantizer): Identity()\n",
       "        )\n",
       "        (proj): Sequential(\n",
       "          (conv): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (residual_quantizer): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (features): Sequential(\n",
       "    (conv): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (activation): SiLU(inplace=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (squeeze): Flatten()\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (fc): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "efficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\n",
    "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\n",
    "efficientnet.eval().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 1224712 images, Test set: 306179 images\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Base directory containing all category subdirectories\n",
    "base_dir = \"/vol/scratch/SoC/misc/2024/sc21cm/train_256_places365standard/data_256/\"\n",
    "\n",
    "# Define transformation pipeline (resize, normalize)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize to match EfficientNet input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Collect all image paths and labels\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for main_dir in os.listdir(base_dir):\n",
    "    main_path = os.path.join(base_dir, main_dir)\n",
    "    if os.path.isdir(main_path):\n",
    "        for place in os.listdir(main_path):\n",
    "            place_path = os.path.join(main_path, place)\n",
    "            if os.path.isdir(place_path):\n",
    "                files = [os.path.join(place_path, f) for f in os.listdir(place_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "                image_paths.extend(files)\n",
    "                labels.extend([f\"{main_dir}/{place}\"] * len(files))\n",
    "\n",
    "# Shuffle dataset (combined image paths and labels) before splitting\n",
    "combined = list(zip(image_paths, labels))\n",
    "random.shuffle(combined)\n",
    "image_paths, labels = zip(*combined)\n",
    "\n",
    "# Create a mapping of label names to numeric indices\n",
    "unique_labels = sorted(set(labels))\n",
    "label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "# Convert labels to indices\n",
    "numeric_labels = [label_to_index[label] for label in labels]\n",
    "\n",
    "# Split dataset (80 for training, 20 for testing)\n",
    "train_paths, train_labels = image_paths[:int(0.8 * len(image_paths))], numeric_labels[:int(0.8 * len(numeric_labels))]\n",
    "test_paths, test_labels = image_paths[int(0.8 * len(image_paths)):], numeric_labels[int(0.8 * len(numeric_labels)):]\n",
    "# train_paths, train_labels = image_paths[:800], numeric_labels[:1000]\n",
    "# test_paths, test_labels = image_paths[800:1000], numeric_labels[800:1000]\n",
    "# Define PyTorch dataset\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Create Dataset & DataLoader\n",
    "train_dataset = ImageDataset(train_paths, train_labels, transform=transform)\n",
    "test_dataset = ImageDataset(test_paths, test_labels, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=8, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True, num_workers=8, pin_memory=True)\n",
    "\n",
    "print(f\"Train set: {len(train_dataset)} images, Test set: {len(test_dataset)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'classmapping.csv' has been created.\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "filename = \"classmapping.csv\"\n",
    "\n",
    "with open(filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for key, value in label_to_index.items():\n",
    "        writer.writerow([value  , key[2:]])\n",
    "\n",
    "print(f\"CSV file '{filename}' has been created.\")\n",
    "print(len(label_to_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Modify the classifier to match the number of classes\n",
    "num_classes = len(unique_labels)\n",
    "efficientnet.classifier.fc = nn.Linear(efficientnet.classifier.fc.in_features, num_classes)\n",
    "efficientnet.to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(efficientnet.parameters(), lr=0.0001)  # Small LR for fine-tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = {}\n",
    "for main_dir in os.listdir(base_dir):\n",
    "    main_path = os.path.join(base_dir, main_dir)\n",
    "    if os.path.isdir(main_path):\n",
    "        for place in os.listdir(main_path):\n",
    "            place_path = os.path.join(main_path, place)\n",
    "            if os.path.isdir(place_path):\n",
    "                num_files = len([f for f in os.listdir(place_path) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "                label = f\"{main_dir}/{place}\"\n",
    "                label_counts[label] = num_files\n",
    "\n",
    "total_samples = sum(label_counts.values())\n",
    "\n",
    "class_weights = {label: total_samples / count for label, count in label_counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample labels from train_dataset: [29, 29, 49, 47, 17, 18, 6, 16, 47, 21]\n",
      "Expected labels in class_weights: ['a/airport_and_airplane', 'a/arabic_cityscape', 'a/art', 'a/amusement_park', 'a/arcade', 'a/army_base', 'b/bar_and_pub', 'b/building_inside', 'b/building', 'b/boats_and_ports']\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample labels from train_dataset:\", train_dataset.labels[:10])\n",
    "print(\"Expected labels in class_weights:\", list(class_weights.keys())[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from torch.cuda.amp import GradScaler, autocast  # For mixed precision training\n",
    "\n",
    "# Compute class weights efficiently\n",
    "print('1')\n",
    "label_to_index = {label: idx for idx, label in enumerate(class_weights.keys())}\n",
    "index_to_weight = {idx: class_weights[label] for label, idx in label_to_index.items()}\n",
    "\n",
    "# Convert labels to corresponding weights\n",
    "weights = torch.tensor([index_to_weight[label] for label in train_dataset.labels], dtype=torch.float32)\n",
    "print('2')\n",
    "# Use WeightedRandomSampler to handle imbalance\n",
    "sampler = torch.utils.data.WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
    "print('3')\n",
    "\n",
    "# Define loss function with class weights\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor(list(class_weights.values())).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 76.52159352194342, 1: 78.82657947582514, 2: 76.54455, 3: 102.0594, 4: 153.0891, 5: 306.1782, 6: 76.54455, 7: 35.019810133821345, 8: 30.61782, 9: 61.23564, 10: 153.0891, 11: 153.0891, 12: 153.0891, 13: 102.0594, 14: 61.23564, 15: 45.536482346292274, 16: 102.0594, 17: 34.0198, 18: 61.23564, 19: 353.5545034642032, 20: 153.0891, 21: 306.1782, 22: 34.0198, 23: 153.0891, 24: 102.47613628756945, 25: 154.54179285281649, 26: 34.0198, 27: 103.25718332658843, 28: 76.54455, 29: 14.579914285714286, 30: 45.61517833199249, 31: 44.804817372980565, 32: 153.0891, 33: 128.4735649546828, 34: 153.0891, 35: 306.1782, 36: 76.54455, 37: 306.1782, 38: 15.30891, 39: 61.23564, 40: 76.54455, 41: 306.1782, 42: 306.1782, 43: 153.0891, 44: 51.0297, 45: 102.0594, 46: 30.61782, 47: 23.902618389620123, 48: 153.0891, 49: 12.586665899299504, 50: 27.834381818181818, 51: 76.54455, 52: 76.54455, 53: 102.0594, 54: 76.54455, 55: 156.0700377204608, 56: 153.0891, 57: 16.114642105263158}\n"
     ]
    }
   ],
   "source": [
    "print(index_to_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set up\n",
      "Scaler set up\n",
      "Loaded the best model checkpoint.\n"
     ]
    }
   ],
   "source": [
    "# Training setup\n",
    "print('Training set up')\n",
    "num_epochs = 2  # Adjust as needed\n",
    "efficientnet.train()\n",
    "best_loss = float('inf')\n",
    "patience_counter = 0\n",
    "patience = 5  # Early stopping patience\n",
    "\n",
    "# Enable mixed precision training\n",
    "print('Scaler set up')\n",
    "scaler = torch.amp.GradScaler('cuda',enabled=True)\n",
    "\n",
    "try:\n",
    "    efficientnet.load_state_dict(torch.load(\"best_efficientnet57.pth\"))\n",
    "    print(\"Loaded the best model checkpoint.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No previous checkpoint found, starting from scratch.\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)  # Faster zeroing\n",
    "\n",
    "        with torch.amp.autocast('cuda'):  # Enable mixed precision\n",
    "            outputs = efficientnet(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        scaler.scale(loss).backward()  # Scale gradients\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted_labels = torch.max(outputs, 1)\n",
    "        correct += (predicted_labels == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(efficientnet.state_dict(), \"best_efficientnet57.pth\")\n",
    "        print(f\"Best model saved with loss: {best_loss:.4f}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "    print(datetime.now())\n",
    "\n",
    "print(\"Training complete!\")\n",
    "torch.save(efficientnet.state_dict(), \"efficientnet57.pth\")\n",
    "print(\"Model saved as efficientnet57.pth\")\n",
    "# 14:47\n",
    "# 43 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet.load_state_dict(torch.load(\"/home/csunix/sc21cm/Desktop/best_efficientnet57.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65597/372363075.py:25: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_65597/372363075.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Mixed Precision\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Backpropagation with mixed precision\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[1;32m     49\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Create a reverse mapping from numeric label to class name\n",
    "index_to_label = {idx: label for label, idx in label_to_index.items()}\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 40\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-4\n",
    "batch_size = 64  # Adjust as needed\n",
    "patience = 5  # Early stopping patience\n",
    "\n",
    "# Set the model to training mode\n",
    "efficientnet.train()\n",
    "\n",
    "# Optimizer and Loss function\n",
    "optimizer = AdamW(efficientnet.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)  # Decay learning rate every 5 epochs\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Mixed precision training setup\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Early stopping variables\n",
    "best_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():  # Mixed Precision\n",
    "            # Forward pass\n",
    "            outputs = efficientnet(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backpropagation with mixed precision\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Get predictions\n",
    "        _, predicted_labels = torch.max(outputs, 1)\n",
    "        correct += (predicted_labels == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    # Calculate training accuracy\n",
    "    train_accuracy = 100 * correct / total\n",
    "\n",
    "    # Print training progress\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    # Learning rate scheduling\n",
    "    scheduler.step()\n",
    "\n",
    "    # Early stopping based on loss\n",
    "    if running_loss < best_loss:\n",
    "        best_loss = running_loss\n",
    "        patience_counter = 0\n",
    "        # Save model checkpoint\n",
    "        torch.save(efficientnet.state_dict(), \"best_efficientnet.pth\")\n",
    "        print(f\"Best model saved with loss: {best_loss:.4f}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Load the best model (optional, if you need to resume or evaluate)\n",
    "efficientnet.load_state_dict(torch.load(\"best_efficientnet.pth\"))\n",
    "print(\"Model loaded: best_efficientnet.pth\")\n",
    "\n",
    "# Final model saving after all training epochs\n",
    "torch.save(efficientnet.state_dict(), \"efficientnet_finetuned.pth\")\n",
    "print(\"Final model saved as efficientnet_finetuned.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 80.13%\n",
      "Macro F1 Score: 0.7940\n",
      "Weighted F1 Score: 0.7950\n"
     ]
    }
   ],
   "source": [
    "# Set model to evaluation mode\n",
    "efficientnet.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Create reverse mapping from numeric labels to class names (for display)\n",
    "index_to_label = {idx: label for label, idx in label_to_index.items()}\n",
    "\n",
    "# For calculating F1 score\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = efficientnet(images)\n",
    "        _, predicted = torch.max(outputs, 1)  # Get class with highest probability\n",
    "        \n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        # Store predictions and labels for F1 score calculation\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Print predictions for each image in the batch\n",
    "        # for i in range(len(labels)):\n",
    "        #     predicted_label_name = index_to_label[predicted[i].item()]\n",
    "        #     ground_truth_label_name = index_to_label[labels[i].item()]\n",
    "            # print(f\"Image {i+1}: Predicted: {predicted_label_name}, Ground Truth: {ground_truth_label_name}\")\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Calculate F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# For binary classification\n",
    "if len(set(all_labels)) == 2:\n",
    "    f1 = f1_score(all_labels, all_predictions)\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "# For multi-class classification\n",
    "else:\n",
    "    # Calculate macro F1 (average of F1 for each class)\n",
    "    f1_macro = f1_score(all_labels, all_predictions, average='macro')\n",
    "    # Calculate weighted F1 (weighted by class frequency)\n",
    "    f1_weighted = f1_score(all_labels, all_predictions, average='weighted')\n",
    "    print(f\"Macro F1 Score: {f1_macro:.4f}\")\n",
    "    print(f\"Weighted F1 Score: {f1_weighted:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '_tkinter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtkinter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtk\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtkinter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m filedialog\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load trained model\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/tkinter/__init__.py:38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtypes\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_tkinter\u001b[39;00m \u001b[38;5;66;03m# If this fails your Python may not be configured for Tk\u001b[39;00m\n\u001b[1;32m     39\u001b[0m TclError \u001b[38;5;241m=\u001b[39m _tkinter\u001b[38;5;241m.\u001b[39mTclError\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtkinter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '_tkinter'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load trained model\n",
    "model = efficientnet  # Ensure you have your model loaded\n",
    "model.load_state_dict(torch.load(\"efficientnet_finetuned.pth\", map_location=torch.device(\"mps\")))\n",
    "model.eval()\n",
    "\n",
    "# Reverse label mapping\n",
    "index_to_label = {idx: label for label, idx in label_to_index.items()}\n",
    "\n",
    "# Define transformation (must match training!)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Function to load and classify an image\n",
    "def classify_image():\n",
    "    # Manually input image path\n",
    "    file_path = input(\"Enter the path to your image: \")\n",
    "\n",
    "    try:\n",
    "        # Load and preprocess image\n",
    "        image = Image.open(file_path).convert(\"RGB\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found. Please check the path and try again.\")\n",
    "        return\n",
    "\n",
    "    # Preprocess image\n",
    "    input_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    input_tensor = input_tensor.to(\"mps\")\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "        _, predicted_label = torch.max(outputs, 1)\n",
    "    \n",
    "    predicted_class = index_to_label[predicted_label.item()]\n",
    "    \n",
    "    # Display image and prediction\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Predicted Label: {predicted_class}\")\n",
    "    plt.show()\n",
    "\n",
    "# Run the function\n",
    "classify_image()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
